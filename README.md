# üîç Files Semantic Search

An AI-powered file search tool that finds files by meaning, not just keywords. Uses vector embeddings to understand context and find relevant files even when they use different terminology.

(Most, if not all, code and files are generated by ChatGPT and Claude.)

## ‚ú® Key Features

- **üß† Semantic Understanding**: Finds files by meaning, not just exact word matches
- **‚ö° Fast Performance**: Optimized scanning with GPU acceleration support
- **üíæ Smart Caching**: Skips unchanged files for faster subsequent searches
- **üéØ Flexible Models**: Choose from fast, balanced, or high-quality AI models
- **üìä Progress Tracking**: Real-time progress with detailed feedback
- **üõ†Ô∏è Enhanced Context**: Includes file paths and names in search context

## üöÄ Quick Start

### Basic Usage

```bash
# Simple search
python file_search.py "machine learning code"

# With caching for faster repeated searches
python file_search.py "database connection" --cache

# Fast model for large codebases
python file_search.py "authentication logic" --model fast

# High quality search with more results
python file_search.py "error handling" --model best -k 15
```

### Advanced Usage

```bash
# Specific file types only
python file_search.py "React components" --extensions .js .jsx .ts .tsx

# Debug mode to see all scores
python file_search.py "utility functions" --debug --min-score 0.0

# Performance tuning
python file_search.py "test files" --threads 16 --gpu-batch-size 512 --perf-report
```

## üìÅ File Structure

```txt
semantic-file-search/
‚îú‚îÄ‚îÄ file_search.py      # üéØ Main entry point and CLI
‚îú‚îÄ‚îÄ config.py          # ‚öôÔ∏è Configuration management
‚îú‚îÄ‚îÄ file_processor.py  # üìÇ File scanning and text extraction
‚îú‚îÄ‚îÄ vector_db.py       # ü§ñ AI model and vector database
‚îú‚îÄ‚îÄ utils.py           # üõ†Ô∏è Utilities (spinner, progress, caching)
‚îî‚îÄ‚îÄ README.md          # üìñ This documentation
```

## üîß Installation

### Prerequisites

```bash
pip install chromadb sentence-transformers unstructured python-magic-bin torch
```

### GPU Acceleration (Optional but Recommended)

```bash
# For NVIDIA GPUs with CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## üéõÔ∏è Command Line Options

### Essential Options

| Option | Description | Example |
|--------|-------------|---------|
| `query` | What to search for | `"machine learning code"` |
| `-k, --top-k` | Max results (1-100) | `-k 5` |
| `-s, --min-score` | Similarity threshold (0.0-1.0) | `-s 0.7` |
| `-r, --root-dir` | Directory to search | `-r "C:/Projects"` |
| `-m, --model` | AI model to use | `--model fast` |

### Performance Options

| Option | Description | Example |
|--------|-------------|---------|
| `--cache` | Enable smart caching | `--cache` |
| `--threads N` | Worker threads | `--threads 16` |
| `--gpu-batch-size N` | GPU batch size | `--gpu-batch-size 512` |
| `--no-gpu` | Disable GPU | `--no-gpu` |

### File Filtering

| Option | Description | Example |
|--------|-------------|---------|
| `--extensions` | File types to include | `--extensions .py .js .md` |
| `--max-size MB` | Max file size | `--max-size 500` |
| `--max-files N` | Limit total files | `--max-files 1000` |

### Development & Debug

| Option | Description | Example |
|--------|-------------|---------|
| `--debug` | Show detailed info | `--debug` |
| `--verbose` | Technical logging | `--verbose` |
| `--perf-report` | Performance breakdown | `--perf-report` |

## ü§ñ AI Model Selection

### Quick Reference

| Model | Speed | Quality | Best For |
|-------|-------|---------|----------|
| `fast` | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | Large codebases, quick results |
| `A` (default) | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Balanced speed and quality |
| `B` | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Better accuracy, still fast |
| `best` | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Research, critical searches |
| `code` | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Programming files |
| `multi` | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Multiple languages |

### Examples

```bash
# Speed priority - fastest processing
python file_search.py "API endpoints" --model fast

# Balanced (recommended) - good speed and quality  
python file_search.py "user authentication" --model A

# Quality priority - best accuracy
python file_search.py "algorithm research" --model best

# Code-specific - understands programming concepts
python file_search.py "database queries" --model code
```

## üìä Understanding Results

### Similarity Scores

- **0.8-1.0**: Very similar files (exact matches, same topic)
- **0.6-0.8**: Quite similar files (related functionality)
- **0.4-0.6**: Somewhat related files (same domain)
- **0.2-0.4**: Loosely related files (may contain relevant info)
- **0.0-0.2**: Minimal similarity (likely not relevant)

### Example Output

```txt
üéØ Found 5 relevant files for 'authentication code':
============================================================
 1. [0.847] src/auth/login.py
 2. [0.723] utils/user_validation.js  
 3. [0.681] components/SignIn.tsx
 4. [0.634] middleware/auth_middleware.py
 5. [0.592] tests/test_authentication.py
============================================================
```

## ‚ö° Performance Tips

### First Run vs Subsequent Runs

- **First run**: Builds search index (slower, ~2-10 minutes)
- **Later runs**: Uses cached index (fast, ~5-30 seconds)
- **With --cache**: Skips unchanged files (much faster)

### Speed Optimizations

```bash
# Fastest possible search
python file_search.py "query" --model fast --cache --priority-exts

# For large projects (limit files for testing)
python file_search.py "query" --max-files 1000 --model fast

# Multi-core optimization
python file_search.py "query" --threads 16 --gpu-batch-size 512
```

### Memory Management

- **Large projects**: Use `--model fast` or `--model tiny`
- **Memory issues**: Reduce `--gpu-batch-size` to 128 or 64
- **Very large**: Use `--max-files` to limit processing
- Automatic garbage collection every 1000 files

## üîç Search Strategies

### Finding Code

```bash
# Programming concepts
python file_search.py "error handling patterns" --model code
python file_search.py "database connection logic" --extensions .py .js .ts
python file_search.py "REST API endpoints" --model code

# Specific technologies
python file_search.py "React component state management"
python file_search.py "SQL query optimization" 
python file_search.py "async await patterns"
```

### Finding Documentation

```bash
# Documentation and guides
python file_search.py "installation instructions" --extensions .md .txt .rst
python file_search.py "API documentation" --model best
python file_search.py "troubleshooting guide"
```

### Finding Configuration

```bash
# Config and setup files
python file_search.py "database configuration" --extensions .json .yaml .cfg
python file_search.py "environment variables" --extensions .env .config
python file_search.py "build settings" --extensions .json .yaml .toml
```

## üêõ Troubleshooting

### Common Issues

**Slow Performance**

```bash
# Try faster model
python file_search.py "query" --model fast

# Limit files for testing
python file_search.py "query" --max-files 1000

# Check if GPU is working
python file_search.py "query" --debug  # Look for GPU detection info
```

**No Results Found**

```bash
# Lower the threshold to see all results
python file_search.py "query" --min-score 0.0 --debug

# Try different model
python file_search.py "query" --model best

# Check what files are being processed
python file_search.py "query" --debug --verbose
```

**Memory Issues**

```bash
# Use smaller model
python file_search.py "query" --model tiny

# Reduce GPU batch size
python file_search.py "query" --gpu-batch-size 64

# Force CPU-only mode
python file_search.py "query" --no-gpu
```

**GPU Not Working**

```bash
# Check CUDA installation
python -c "import torch; print(torch.cuda.is_available())"

# Force CPU mode
python file_search.py "query" --no-gpu

# Install GPU-enabled PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Debug Mode

Use `--debug` to see detailed information:

- File processing statistics
- Search score breakdown  
- Hardware detection results
- Performance bottlenecks

```bash
python file_search.py "query" --debug --perf-report
```

## üîÑ What's New

### Performance Improvements

- ‚ö° **Faster Startup**: Deferred imports, show config immediately
- üöÄ **Optimized Scanning**: Smart directory traversal, skip build folders
- üìä **Live Progress**: Real-time progress for both scanning and indexing
- üíæ **Better Caching**: Smarter file change detection
- üéØ **Priority Processing**: Common file types processed first

### Enhanced Context

- üìÅ **Path Awareness**: File paths included in search context
- üè∑Ô∏è **Better Naming**: Filenames and directory names boost relevance
- üîç **Improved Matching**: Finds files even with different terminology

### Modular Architecture

- üìÇ **Split Files**: Organized into logical modules
- üõ†Ô∏è **Better Maintenance**: Easier to extend and modify
- üìñ **Clear Documentation**: Comprehensive help and examples